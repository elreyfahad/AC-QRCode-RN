{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_sparse_data_and_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mNCLhxsXyOIS",
        "eQS5KQzBybTY",
        "copyright-notice"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elreyfahad/AC-QRCode-RN/blob/master/intro_to_sparse_data_and_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright-notice"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "copyright-notice2",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTaAdgy3LS8W",
        "colab_type": "text"
      },
      "source": [
        " # Introduction aux données rares et aux représentations vectorielles continues\n",
        "\n",
        "**Objectifs d'apprentissage :**\n",
        "* Convertir des données de chaîne de critique de film en un vecteur de caractéristique clairsemée\n",
        "* Mettre en œuvre un modèle linéaire d'analyse des sentiments à l'aide d'un vecteur de caractéristique clairsemée\n",
        "* Mettre en œuvre un modèle DNN d'analyse des sentiments à l'aide d'une représentation vectorielle continue qui projette des données dans deux dimensions\n",
        "* Visualiser des représentations vectorielles continues pour déterminer ce que le modèle a appris sur les relations entre les mots\n",
        "\n",
        "Dans cet exercice, nous allons examiner des données rares et travailler avec les représentations vectorielles continues à l'aide de données textuelles issues de critiques de films (provenant de l'[ensemble de données IMDB ACL 2011](http://ai.stanford.edu/~amaas/data/sentiment/)). Ces données ont déjà été traitées au format `tf.Example`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKGtmwNosU8",
        "colab_type": "text"
      },
      "source": [
        " ## Configuration\n",
        "\n",
        "Nous allons importer nos dépendances, et télécharger les données de test et d'apprentissage. [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) comprend un outil de mise en cache et de téléchargement de fichiers que nous pouvons utiliser pour récupérer les ensembles de données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWqDqFFL_NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W7aZ9qspZVj",
        "colab_type": "text"
      },
      "source": [
        " ## Construction d'un modèle d'analyse des sentiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jieA0k_NLS8a",
        "colab_type": "text"
      },
      "source": [
        " Vous allez effectuer, sur ces données, l'entraînement d'un modèle d'analyse des sentiments qui prédit si une critique est globalement *favorable* (libellé 1) ou *défavorable* (libellé 0).\n",
        "\n",
        "Pour ce faire, vous allez transformer la valeur de chaîne `terms` en vecteurs de caractéristiques en utilisant un *vocabulaire*, c'est-à-dire une liste de termes que vous vous attendez à trouver dans nos données. Pour les besoins de cet exercice, nous avons créé un vocabulaire réduit qui porte sur un ensemble limité de termes. Il s'est avéré que la plupart de ces termes indiquaient clairement un fort sentiment *favorable* ou *défavorable*. D'autres cependant ont simplement été ajoutés, car ils étaient intéressants.\n",
        "\n",
        "Chaque terme du vocabulaire est associé à une coordonnée du vecteur de caractéristiques. Pour convertir la valeur de chaîne `terms` d'un exemple dans ce format de vecteur, vous allez coder comme suit : chaque coordonnée reçoit la valeur 0 si le terme de vocabulaire ne figure pas dans l'exemple de chaîne, et la valeur 1 dans le cas contraire. Les termes qui ne figurent pas dans le vocabulaire sont rejetés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HSfklfnLS8b",
        "colab_type": "text"
      },
      "source": [
        " **REMARQUE :** *Vous pourriez bien sûr utiliser un vocabulaire plus vaste ; il existe de nombreux outils spécialisés pour cela. Au lieu de simplement ignorer les termes qui ne figurent pas dans le vocabulaire, vous pourriez également introduire un petit nombre de segments OOV pour hacher les termes hors vocabulaire. Vous pourriez aussi utiliser une méthode axée sur le __hachage de caractéristiques__ qui hache chaque terme, au lieu de créer un vocabulaire explicite. Cela fonctionne très bien dans la pratique, mais au détriment de l'interprétabilité, qui s'avère utile pour cet exercice. Pour consulter les outils adaptés à ce type d'opération, reportez-vous au module tf.feature_column.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvoa2HyDtgqe",
        "colab_type": "text"
      },
      "source": [
        " ## Construction du pipeline d'entrée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O20vMEOurDol",
        "colab_type": "text"
      },
      "source": [
        " Commencez par créer le pipeline d'entrée pour importer les données dans un modèle TensorFlow. Vous pouvez utiliser la fonction suivante pour analyser les données de test et d'apprentissage (qui se trouvent au format [TFRecord](https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data)), et renvoyer un dictionnaire des caractéristiques et les libellés correspondants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxNIEniPq2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return  {'terms':terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXhTeeYMrp-l",
        "colab_type": "text"
      },
      "source": [
        " Pour vérifier que cela fonctionne comme prévu, construisez un ensemble `TFRecordDataset` pour les données d'apprentissage, et associez ces dernières aux caractéristiques et aux libellés à l'aide de la fonction ci-dessus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF4YWXR0Omt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)\n",
        "\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUoMvK-9tVXP",
        "colab_type": "text"
      },
      "source": [
        " Exécutez la cellule suivante pour récupérer le premier exemple de l'ensemble de données d'apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6QE2DWRUc4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()\n",
        "sess.run(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBU39UeFty9S",
        "colab_type": "text"
      },
      "source": [
        " Vous allez maintenant construire une fonction d'entrée formelle que vous pouvez transmettre à la méthode `train()` d'un objet TensorFlow Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_C5-ueNYIn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input_fn that parses the tf.Examples from the given files,\n",
        "# and split them into features and targets.\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "  \n",
        "  # Same code as above; create a dataset and map features and labels.\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  # Our feature data is variable-length, so we pad and batch\n",
        "  # each field of the dataset structure to whatever size is necessary.     \n",
        "  ds = ds.padded_batch(25, ds.output_shapes)\n",
        "  \n",
        "  ds = ds.repeat(num_epochs)\n",
        "\n",
        "  \n",
        "  # Return the next batch of data.\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y170tVlrLS8c",
        "colab_type": "text"
      },
      "source": [
        " ## Tâche 1 : Utiliser un modèle linéaire avec des entrées clairsemées et un vocabulaire explicite\n",
        "\n",
        "Pour le premier modèle, vous allez construire un modèle [`LinearClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) à l'aide de 50 termes informatifs ; commencez toujours simplement !\n",
        "\n",
        "Le code suivant construit la colonne de caractéristiques pour ces termes. La fonction [`categorical_column_with_vocabulary_list`](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list) crée une colonne de caractéristiques avec la mise en correspondance chaîne/vecteur de caractéristiques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5gdxuWsvPcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 50 informative terms that compose our model vocabulary. \n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTiDwyorwd3P",
        "colab_type": "text"
      },
      "source": [
        " Vous allez ensuite construire le modèle `LinearClassifier`, l'entraîner sur l'ensemble d'apprentissage et l'évaluer sur l'ensemble d'évaluation. Après avoir parcouru le code, exécutez-le et voyons comment vous vous en sortez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYKKpGLqLS8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [ terms_feature_column ]\n",
        "\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ubn9gULS8g",
        "colab_type": "text"
      },
      "source": [
        " ## Tâche 2 : Utiliser un modèle de réseau neuronal profond (DNN)\n",
        "\n",
        "Le modèle ci-dessus est de type linéaire. Il fonctionne relativement bien. Cependant, peut-on obtenir de meilleurs résultats avec un modèle DNN ?\n",
        "\n",
        "Remplaçons le modèle `LinearClassifier` par le modèle [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier). Exécutez la cellule suivante et voyons comment vous vous en sortez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcgOPfEALS8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################### Here's what we changed ##################################\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000)\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1)\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([test_path]),\n",
        "    steps=1)\n",
        "\n",
        "  print(\"Test set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZz68luxLS8j",
        "colab_type": "text"
      },
      "source": [
        " ## Tâche 3 : Utiliser une représentation vectorielle continue avec un modèle DNN\n",
        "\n",
        "Dans le cadre de cette tâche, vous allez mettre en œuvre un modèle DNN à l'aide d'une colonne de représentations vectorielles continues. Une colonne de ce type accepte des données rares en guise d'entrée et renvoie un vecteur dense de plus faible dimension en sortie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliRzhvJLS8k",
        "colab_type": "text"
      },
      "source": [
        " **REMARQUE :** *En règle générale, une colonne de représentations vectorielles continues constitue l'option la plus efficace du point de vue de l'utilisation des ressources pour entraîner un modèle sur des données rares. Dans une [section facultative](#scrollTo=XDMlGgRfKSVz) à la fin de cet exercice, nous examinerons plus en détail les différences de mise en œuvre entre l'utilisation des options `embedding_column` et `indicator_column`, ainsi que les avantages et inconvénients de ces deux options.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-as3PtALS8l",
        "colab_type": "text"
      },
      "source": [
        " Effectuez ce qui suit dans le code ci-dessous :\n",
        "\n",
        "* Définissez les colonnes de caractéristiques pour le modèle à l'aide d'une option `embedding_column` qui projette les données dans deux dimensions (voir les [documents TF](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) pour en savoir plus sur la signature de fonction pour `embedding_column`).\n",
        "* Définissez un modèle `DNNClassifier` avec les spécifications suivantes :\n",
        "  * Deux couches cachées de 20 unités chacune\n",
        "  * Une optimisation AdaGrad avec un taux d'apprentissage de 0,1\n",
        "  * Une valeur `gradient_clip_norm` de 5,0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlPZ-Q9bLS8m",
        "colab_type": "text"
      },
      "source": [
        " **REMARQUE :** *Dans la pratique, vous pourriez projeter des données dans un nombre de dimensions supérieur à 2 ; 50 ou 100, par exemple. Cependant, pour l'instant, se limiter à deux dimensions permet une visualisation aisée.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNCLhxsXyOIS",
        "colab_type": "text"
      },
      "source": [
        " ### Astuce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L67xYD7hLS8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's a example code snippet you might use to define the feature columns:\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv1UBsJxyV37",
        "colab_type": "text"
      },
      "source": [
        " ### Exécutez le code ci-dessous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PG_yhNGLS8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## YOUR CODE HERE ######################################\n",
        "terms_embedding_column = # Define the embedding column\n",
        "feature_columns = # Define the feature columns\n",
        "\n",
        "classifier = # Define the DNNClassifier\n",
        "################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQS5KQzBybTY",
        "colab_type": "text"
      },
      "source": [
        " ### Solution\n",
        "\n",
        "Cliquez ci-dessous pour afficher la solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xOdYeQydi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## SOLUTION CODE ########################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "#################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHnnVtzLS8w",
        "colab_type": "text"
      },
      "source": [
        " ## Tâche 4 : Se convaincre qu'il existe réellement une représentation vectorielle continue\n",
        "\n",
        "L'option `embedding_column` est utilisée dans le modèle ci-dessus et cela semble fonctionner. Cependant, cela ne nous donne pas beaucoup d'informations sur ce qui se passe en interne. Dans ce cas, comment vérifier que le modèle utilise effectivement une représentation vectorielle continue en interne ?\n",
        "\n",
        "Pour commencer, examinez les Tensors qui se trouvent dans le modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1jNgLdQLS8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.get_variable_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl4-VctMLS8z",
        "colab_type": "text"
      },
      "source": [
        " Comme vous pouvez le voir, le modèle contient une couche de représentations vectorielles continues : `'dnn/input_from_feature_columns/input_layer/terms_embedding/...'`. (Ce qui est intéressant ici, c'est que cette couche peut être apprise avec le reste du modèle, comme c'est le cas pour n'importe quelle couche cachée.)\n",
        "\n",
        "La forme de la couche de représentations vectorielles continues est-elle correcte ? Pour le savoir, exécutez le code suivant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFxyQUiLS80",
        "colab_type": "text"
      },
      "source": [
        " **REMARQUE :** *Dans le cas présent, souvenez-vous que la représentation vectorielle continue est une matrice qui nous permet de projeter un vecteur allant de 50 dimensions jusqu'à 2 dimensions.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xMbpcEjLS80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights').shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLCIogjLS82",
        "colab_type": "text"
      },
      "source": [
        " Consacrez du temps à la vérification manuelle des différentes couches et formes pour vous assurer que tout est correctement connecté."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkKAaRWDLS83",
        "colab_type": "text"
      },
      "source": [
        " ## Tâche 5 : Examiner la représentation vectorielle continue\n",
        "\n",
        "Nous allons à présent nous pencher sur l'espace de représentation vectorielle proprement dit et voir où se classent les termes. Pour cela, procédez comme suit :\n",
        "1. Exécutez le code suivant pour voir la représentation vectorielle continue dont vous avez effectué l'apprentissage à la **Tâche 3**. Est-ce que tout est conforme à vos attentes ?\n",
        "\n",
        "2. Entraînez à nouveau le modèle en exécutant une nouvelle fois le code de la **Tâche 3**, puis exécutez à nouveau la visualisation des représentations vectorielles continues ci-dessous. Quels sont les changements ? Quels sont les éléments qui restent identiques ?\n",
        "\n",
        "3. Pour terminer, entraînez à nouveau le modèle en utilisant seulement 10 mesures (ce qui donnera lieu à un très mauvais modèle). Exécutez à nouveau la représentation vectorielle continue ci-dessous. Que voyez-vous maintenant, et pourquoi ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4NNu7KqLS84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "embedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')\n",
        "\n",
        "for term_index in range(len(informative_terms)):\n",
        "  # Create a one-hot encoding for our term.  It has 0s everywhere, except for\n",
        "  # a single 1 in the coordinate that corresponds to that term.\n",
        "  term_vector = np.zeros(len(informative_terms))\n",
        "  term_vector[term_index] = 1\n",
        "  # We'll now project that one-hot vector into the embedding space.\n",
        "  embedding_xy = np.matmul(term_vector, embedding_matrix)\n",
        "  plt.text(embedding_xy[0],\n",
        "           embedding_xy[1],\n",
        "           informative_terms[term_index])\n",
        "\n",
        "# Do a little setup to make sure the plot displays nicely.\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
        "plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUb3L7pqLS86",
        "colab_type": "text"
      },
      "source": [
        " ## Tâche 6 : Essayer d'améliorer les performances du modèle\n",
        "\n",
        "Voyez s'il est possible d'affiner le modèle afin d'en améliorer les performances. Voici quelques pistes :\n",
        "\n",
        "* **Modifier les hyperparamètres** ou **utiliser un autre optimiseur** comme Adam (ces stratégies vous permettront de gagner, tout au plus, un ou deux points de pourcentage de précision).\n",
        "* **Ajouter des termes aux `informative_terms`.** Vous trouverez, à l'adresse suivante, un fichier de vocabulaire complet contenant 30 716 termes pour cet ensemble de données : https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt. Vous pouvez choisir des termes supplémentaires dans ce fichier ou l'utiliser intégralement via la colonne de caractéristiques `categorical_column_with_vocabulary_file`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-b3BqXvLS86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the vocabulary file.\n",
        "terms_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt'\n",
        "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbJlwW5LS8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a feature column from \"terms\", using a full vocabulary file.\n",
        "informative_terms = None\n",
        "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
        "  # Convert it to a set first to remove duplicates.\n",
        "  informative_terms = list(set(f.read().split()))\n",
        "  \n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", \n",
        "                                                                                 vocabulary_list=informative_terms)\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[10,10],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew3kwGM-LS9B",
        "colab_type": "text"
      },
      "source": [
        " ## Le mot de la fin\n",
        "\n",
        "La solution DNN avec représentation vectorielle continue que nous avons développée est peut-être meilleure que notre modèle linéaire d'origine. Cependant, ce dernier offrait également de bons résultats et son apprentissage s'avérait bien plus rapide. Cette vitesse d'apprentissage est due au fait que les modèles linéaires ne comptent pas autant de paramètres à mettre à jour, ni autant de couches à traverser pour la rétropropagation.\n",
        "\n",
        "Pour certaines applications, la vitesse des modèles linéaires peut changer la donne ou, d'un point de vue qualitatif, ces modèles peuvent s'avérer bien suffisants. Dans d'autres cas, la complexité accrue du modèle et la capacité fournie par les solutions DNN peuvent être plus importantes. Lorsque vous définissez l'architecture de votre modèle, étudiez le problème de manière suffisamment approfondie pour déterminer l'espace dans lequel vous vous trouvez."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MquXy9zLS9B",
        "colab_type": "text"
      },
      "source": [
        " ### *Discussion facultative :* Avantages et inconvénients de l'option `embedding_column` par rapport à `indicator_column`\n",
        "\n",
        "D'un point de vue conceptuel, un adaptateur est nécessaire pour utiliser une colonne de données rares lors de l'apprentissage d'un modèle `LinearClassifier` ou `DNNClassifier`. TF propose deux options : `embedding_column` et `indicator_column`.\n",
        "\n",
        "Lors de l'apprentissage d'un modèle LinearClassifier (comme dans la **Tâche 1**), l'option `embedding_column` est utilisée. Comme nous l'avons vu dans la **Tâche 2**, lors de l'apprentissage d'un modèle `DNNClassifier`, vous devez choisir explicitement `embedding_column` ou `indicator_column`. Cette section décrit la distinction entre ces deux options, ainsi que les avantages et inconvénients de l'une par rapport à l'autre, à l'aide d'un exemple simple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_3XuZ_LLS9C",
        "colab_type": "text"
      },
      "source": [
        " Prenons comme exemple des données rares contenant les valeurs `\"great\"`, `\"beautiful\"` et `\"excellent\"`. Étant donné que la taille du vocabulaire utilisé ici est de $V = 50$, chaque unité (neurone) de la première couche aura 50 pondérations. Pour représenter le nombre de termes d'une entrée clairsemée, nous allons utiliser $s$. Pour cet exemple de données rares, nous avons donc $s = 3$. Pour une couche d'entrée avec $V$ valeurs possibles, une couche cachée avec $d$ unités doit effectuer la multiplication d'un vecteur par une matrice : $(1 \\times V) * (V \\times d)$. Le coût de calcul de cette opération est de $O(V * d)$. Notez que ce coût est proportionnel au nombre de pondérations dans cette couche cachée et indépendant de $s$.\n",
        "\n",
        "Si les entrées sont encodées au format one-hot (un vecteur booléen de longueur $V$ avec la valeur 1 pour les termes présents et la valeur 0 pour le reste) à l'aide de l'option [`indicator_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column), cela signifie qu'une multiplication est nécessaire et qu'il faut ajouter beaucoup de zéros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7mR4Wa2LS9C",
        "colab_type": "text"
      },
      "source": [
        " Lorsque l'on obtient exactement les mêmes résultats en utilisant une option [`embedding_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) de taille $d$, on recherche et on ajoute simplement les représentations vectorielles continues correspondant aux trois caractéristiques présentes dans notre exemple d'entrée de `\"great\"`, `\"beautiful\"`, `\"excellent\"`: $(1 \\times d) + (1 \\times d) + (1 \\times d)$. Étant donné que les pondérations relatives aux caractéristiques qui sont absentes sont multipliées par 0 dans la multiplication d'un vecteur par une matrice, elles n'entrent pas en ligne de compte dans le résultat. Les pondérations relatives aux caractéristiques présentes sont, elles, multipliées par 1. Dès lors, l'ajout des pondérations obtenues par le biais de la recherche des représentations vectorielles continues donnera le même résultat que la multiplication d'un vecteur par une matrice.\n",
        "\n",
        "Lorsque vous utilisez des représentations vectorielles continues, calculer la recherche de ces représentations correspond à $O(s * d)$, ce qui, sur le plan de l'utilisation des ressources, s'avère beaucoup plus efficace que le coût $O(V * d)$ de l'option `indicator_column` dans les données rares, pour laquelle $s$ est sensiblement plus petit que $V$. (Pour rappel, ces représentations vectorielles continues sont en cours d'apprentissage. Dans n'importe quelle itération d'apprentissage, ce sont les pondérations en cours qui sont recherchées.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZ9qf0kLS9D",
        "colab_type": "text"
      },
      "source": [
        " Comme nous l'avons vu dans la **Tâche 3**, lorsque l'on utilise une option `embedding_column` pour effectuer l'apprentissage du modèle `DNNClassifier`, notre modèle apprend une représentation bidimensionnelle des caractéristiques, dans laquelle le produit scalaire définit une statistique de similitude adaptée à la tâche souhaitée. Dans cet exemple, les termes utilisés de la même façon dans le cadre des critiques de films (`\"great\"` et `\"excellent\"`, par exemple) seront plus proches les uns des autres dans l'espace de représentation vectorielle (grand produit scalaire), tandis que les termes dissemblables (`\"great\"` et `\"bad\"`, par exemple) seront plus éloignés (petit produit scalaire)."
      ]
    }
  ]
}